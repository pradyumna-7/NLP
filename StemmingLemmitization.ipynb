{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloading punkt tokenizer models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prady\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # Timer module for performance measurement\n",
    "import wikipediaapi  # Wikipedia API to fetch text\n",
    "import spacy  # NLP library for lemmatization\n",
    "from nltk.stem import PorterStemmer  # Stemming module from nltk\n",
    "from nltk.tokenize import word_tokenize  # Tokenization modul\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching Wikipedia Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fetch Wikipedia content\n",
    "def get_wikipedia_text(page_title):\n",
    "    wiki_wiki = wikipediaapi.Wikipedia(user_agent=\"MyNLPProject/1.0\", language=\"en\")\n",
    "    page = wiki_wiki.page(page_title)\n",
    "    return page.summary if page.exists() else \"\"\n",
    "text = get_wikipedia_text(\"Keshav_Memorial_Institute_of_Technology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokens = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying stemming using PortStemmer in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['keshav',\n",
       " 'memori',\n",
       " 'institut',\n",
       " 'of',\n",
       " 'technolog',\n",
       " 'is',\n",
       " 'a',\n",
       " 'privat',\n",
       " 'engin',\n",
       " 'colleg',\n",
       " 'in',\n",
       " 'hyderabad',\n",
       " 'in',\n",
       " 'telangana',\n",
       " ',',\n",
       " 'india.',\n",
       " 'it',\n",
       " 'offer',\n",
       " 'b.tech',\n",
       " 'degre',\n",
       " 'in',\n",
       " 'comput',\n",
       " 'scienc',\n",
       " 'and',\n",
       " 'engin',\n",
       " ',',\n",
       " 'artifici',\n",
       " 'intellig',\n",
       " 'and',\n",
       " 'machin',\n",
       " 'learn',\n",
       " ',',\n",
       " 'data',\n",
       " 'scienc',\n",
       " ',',\n",
       " 'and',\n",
       " 'inform',\n",
       " 'technolog',\n",
       " '.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Apply Stemming\n",
    "stemmer = PorterStemmer()\n",
    "start_stem = time.time()  # Start timer\n",
    "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
    "end_stem = time.time()  # End timer\n",
    "stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Lemmitization using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Keshav',\n",
       " 'Memorial',\n",
       " 'Institute',\n",
       " 'of',\n",
       " 'Technology',\n",
       " 'be',\n",
       " 'a',\n",
       " 'private',\n",
       " 'engineering',\n",
       " 'college',\n",
       " 'in',\n",
       " 'Hyderabad',\n",
       " 'in',\n",
       " 'Telangana',\n",
       " ',',\n",
       " 'India',\n",
       " '.',\n",
       " 'it',\n",
       " 'offer',\n",
       " 'B.Tech',\n",
       " 'degree',\n",
       " 'in',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'and',\n",
       " 'engineering',\n",
       " ',',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'learning',\n",
       " ',',\n",
       " 'data',\n",
       " 'science',\n",
       " ',',\n",
       " 'and',\n",
       " 'information',\n",
       " 'technology',\n",
       " '.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Apply Lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "start_lem = time.time()  # Start timer\n",
    "doc = nlp(\" \".join(tokens))\n",
    "lemmatized_words = [token.lemma_ for token in doc]\n",
    "end_lem = time.time()  # End timer\n",
    "lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text Sample: ['Keshav', 'Memorial', 'Institute', 'of', 'Technology', 'is', 'a', 'private', 'engineering', 'college']\n",
      "Stemmed Words: ['keshav', 'memori', 'institut', 'of', 'technolog', 'is', 'a', 'privat', 'engin', 'colleg']\n",
      "Lemmatized Words: ['Keshav', 'Memorial', 'Institute', 'of', 'Technology', 'be', 'a', 'private', 'engineering', 'college']\n",
      "\n",
      "Performance Analysis:\n",
      "Stemming Execution Time: 0.00100 seconds\n",
      "Lemmatization Execution Time: 0.01400 seconds\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Display Results\n",
    "print(\"Original Text Sample:\", tokens[:10])\n",
    "print(\"Stemmed Words:\", stemmed_words[:10])\n",
    "print(\"Lemmatized Words:\", lemmatized_words[:10])\n",
    "# Step 5: Performance Comparison\n",
    "print(\"\\nPerformance Analysis:\")\n",
    "print(f\"Stemming Execution Time: {end_stem - start_stem:.5f} seconds\")\n",
    "print(f\"Lemmatization Execution Time: {end_lem - start_lem:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Stemming using Lancaster Stemming in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['keshav', 'mem', 'institut', 'of', 'technolog', 'is', 'a', 'priv', 'engin', 'colleg']\n",
      "Stemming Execution Time: 0.00100 seconds\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "import time\n",
    "\n",
    "# Step 2: Apply Lancaster Stemming\n",
    "stemmer = LancasterStemmer()\n",
    "start_stem = time.time()  # Start timer\n",
    "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
    "end_stem = time.time()  # End timer\n",
    "print(\"Stemmed Words:\", stemmed_words[:10])\n",
    "print(f\"Stemming Execution Time: {end_stem - start_stem:.5f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Stemming using Snowball Stemmer in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['keshav', 'memori', 'institut', 'of', 'technolog', 'is', 'a', 'privat', 'engin', 'colleg']\n",
      "Stemming Execution Time: 0.00100 seconds\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "import time\n",
    "\n",
    "# Step 2: Apply Snowball Stemming\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "start_stem = time.time()  # Start timer\n",
    "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
    "end_stem = time.time()  # End timer\n",
    "print(\"Stemmed Words:\", stemmed_words[:10])\n",
    "print(f\"Stemming Execution Time: {end_stem - start_stem:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Lemmitization using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Words: ['Keshav', 'Memorial', 'Institute', 'of', 'Technology', 'is', 'a', 'private', 'engineering', 'college']\n",
      "Lemmatization Execution Time: 0.00000 seconds\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "start_stem = time.time() \n",
    "# Apply Lemmatization\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "end_stem = time.time()  # End timer\n",
    "\n",
    "print(\"Lemmatized Words:\", lemmatized_words[:10])\n",
    "print(f\"Lemmatization Execution Time: {end_stem - start_stem:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
